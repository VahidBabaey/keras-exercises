{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "sitting-thread",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow import random\n",
    "\n",
    "# Load the Data\n",
    "X = pd.read_csv(\".../aps_failure_training_feats.csv\")\n",
    "y = pd.read_csv(\".../aps_failure_training_target.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "suspected-portsmouth",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "seed = 42\n",
    "X_train, X_test, y_train, y_test= train_test_split(X, y, test_size=0.20, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "northern-recognition",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize StandardScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc=StandardScaler()\n",
    "\n",
    "# Transform the training data\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_train = pd.DataFrame(X_train,columns=X_test.columns)\n",
    "\n",
    "# Transform the testing data\n",
    "X_test=sc.transform(X_test)\n",
    "X_test=pd.DataFrame(X_test,columns=X_train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "appointed-vintage",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the relevant Keras libraries\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "\n",
    "np.random.seed(seed)\n",
    "random.set_seed(seed)\n",
    "model = Sequential()\n",
    "\n",
    "# Add the hidden dense layers and with dropout Layer\n",
    "model.add(Dense(units=64, activation='relu', kernel_initializer='uniform', input_dim=X_train.shape[1]))\n",
    "model.add(Dropout(rate=0.5))\n",
    "model.add(Dense(units=32, activation='relu', kernel_initializer='uniform'))\n",
    "model.add(Dropout(rate=0.4))\n",
    "model.add(Dense(units=16, activation='relu', kernel_initializer='uniform'))\n",
    "model.add(Dropout(rate=0.3))\n",
    "model.add(Dense(units=8, activation='relu', kernel_initializer='uniform'))\n",
    "model.add(Dropout(rate=0.2))\n",
    "model.add(Dense(units=4, activation='relu', kernel_initializer='uniform'))\n",
    "model.add(Dropout(rate=0.1))\n",
    "\n",
    "# Add Output Dense Layer\n",
    "model.add(Dense(units=1, activation='sigmoid', kernel_initializer='uniform'))\n",
    "\n",
    "# Compile the Model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "expensive-cover",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1920/1920 [==============================] - 6s 3ms/step - loss: 0.1644 - accuracy: 0.9825 - val_loss: 0.0351 - val_accuracy: 0.9842\n",
      "Epoch 2/100\n",
      "1920/1920 [==============================] - 4s 2ms/step - loss: 0.0406 - accuracy: 0.9840 - val_loss: 0.0318 - val_accuracy: 0.9842\n",
      "Epoch 3/100\n",
      "1920/1920 [==============================] - 4s 2ms/step - loss: 0.0381 - accuracy: 0.9840 - val_loss: 0.0303 - val_accuracy: 0.9842\n",
      "Epoch 4/100\n",
      "1920/1920 [==============================] - 4s 2ms/step - loss: 0.0342 - accuracy: 0.9840 - val_loss: 0.0313 - val_accuracy: 0.9842\n",
      "Epoch 5/100\n",
      "1920/1920 [==============================] - 4s 2ms/step - loss: 0.0360 - accuracy: 0.9840 - val_loss: 0.0301 - val_accuracy: 0.9842\n",
      "Epoch 6/100\n",
      "1920/1920 [==============================] - 4s 2ms/step - loss: 0.0324 - accuracy: 0.9840 - val_loss: 0.0302 - val_accuracy: 0.9842\n",
      "Epoch 7/100\n",
      "1920/1920 [==============================] - 4s 2ms/step - loss: 0.0321 - accuracy: 0.9860 - val_loss: 0.0294 - val_accuracy: 0.9917\n",
      "Epoch 8/100\n",
      "1920/1920 [==============================] - 4s 2ms/step - loss: 0.0320 - accuracy: 0.9890 - val_loss: 0.0298 - val_accuracy: 0.9921\n",
      "Epoch 9/100\n",
      "1920/1920 [==============================] - 4s 2ms/step - loss: 0.0311 - accuracy: 0.9901 - val_loss: 0.0305 - val_accuracy: 0.9912\n",
      "Epoch 10/100\n",
      "1920/1920 [==============================] - 4s 2ms/step - loss: 0.0287 - accuracy: 0.9897 - val_loss: 0.0278 - val_accuracy: 0.9916\n",
      "Epoch 11/100\n",
      "1920/1920 [==============================] - 4s 2ms/step - loss: 0.0260 - accuracy: 0.9905 - val_loss: 0.0297 - val_accuracy: 0.9911\n",
      "Epoch 12/100\n",
      "1920/1920 [==============================] - 4s 2ms/step - loss: 0.0273 - accuracy: 0.9905 - val_loss: 0.0274 - val_accuracy: 0.9915\n",
      "Epoch 13/100\n",
      "1920/1920 [==============================] - 4s 2ms/step - loss: 0.0272 - accuracy: 0.9910 - val_loss: 0.0280 - val_accuracy: 0.9911\n",
      "Epoch 14/100\n",
      "1920/1920 [==============================] - 4s 2ms/step - loss: 0.0269 - accuracy: 0.9908 - val_loss: 0.0265 - val_accuracy: 0.9930\n",
      "Epoch 15/100\n",
      "1920/1920 [==============================] - 4s 2ms/step - loss: 0.0268 - accuracy: 0.9912 - val_loss: 0.0283 - val_accuracy: 0.9912\n",
      "Epoch 16/100\n",
      "1920/1920 [==============================] - 4s 2ms/step - loss: 0.0261 - accuracy: 0.9906 - val_loss: 0.0263 - val_accuracy: 0.9920\n",
      "Epoch 17/100\n",
      "1920/1920 [==============================] - 4s 2ms/step - loss: 0.0266 - accuracy: 0.9911 - val_loss: 0.0293 - val_accuracy: 0.9916\n",
      "Epoch 18/100\n",
      "1920/1920 [==============================] - 4s 2ms/step - loss: 0.0258 - accuracy: 0.9908 - val_loss: 0.0268 - val_accuracy: 0.9921\n",
      "Epoch 19/100\n",
      "1920/1920 [==============================] - 4s 2ms/step - loss: 0.0242 - accuracy: 0.9919 - val_loss: 0.0256 - val_accuracy: 0.9929\n",
      "Epoch 20/100\n",
      "1920/1920 [==============================] - 4s 2ms/step - loss: 0.0247 - accuracy: 0.9914 - val_loss: 0.0254 - val_accuracy: 0.9926\n",
      "Epoch 21/100\n",
      "1920/1920 [==============================] - 4s 2ms/step - loss: 0.0236 - accuracy: 0.9924 - val_loss: 0.0291 - val_accuracy: 0.9919\n",
      "Epoch 22/100\n",
      "1920/1920 [==============================] - 4s 2ms/step - loss: 0.0243 - accuracy: 0.9913 - val_loss: 0.0254 - val_accuracy: 0.9926\n",
      "Epoch 23/100\n",
      "1920/1920 [==============================] - 4s 2ms/step - loss: 0.0250 - accuracy: 0.9911 - val_loss: 0.0283 - val_accuracy: 0.9926\n",
      "Epoch 24/100\n",
      "1920/1920 [==============================] - 4s 2ms/step - loss: 0.0246 - accuracy: 0.9917 - val_loss: 0.0259 - val_accuracy: 0.9928\n",
      "Epoch 25/100\n",
      "1920/1920 [==============================] - 4s 2ms/step - loss: 0.0234 - accuracy: 0.9922 - val_loss: 0.0246 - val_accuracy: 0.9914\n",
      "Epoch 26/100\n",
      "1920/1920 [==============================] - 4s 2ms/step - loss: 0.0241 - accuracy: 0.9920 - val_loss: 0.0251 - val_accuracy: 0.9935\n",
      "Epoch 27/100\n",
      "1920/1920 [==============================] - 4s 2ms/step - loss: 0.0234 - accuracy: 0.9920 - val_loss: 0.0279 - val_accuracy: 0.9911\n",
      "Epoch 28/100\n",
      "1920/1920 [==============================] - 4s 2ms/step - loss: 0.0245 - accuracy: 0.9918 - val_loss: 0.0255 - val_accuracy: 0.9924\n",
      "Epoch 29/100\n",
      "1920/1920 [==============================] - 4s 2ms/step - loss: 0.0233 - accuracy: 0.9919 - val_loss: 0.0261 - val_accuracy: 0.9924\n",
      "Epoch 30/100\n",
      "1920/1920 [==============================] - 4s 2ms/step - loss: 0.0232 - accuracy: 0.9924 - val_loss: 0.0279 - val_accuracy: 0.9916\n",
      "Epoch 31/100\n",
      "1920/1920 [==============================] - 4s 2ms/step - loss: 0.0233 - accuracy: 0.9925 - val_loss: 0.0249 - val_accuracy: 0.9926\n",
      "Epoch 32/100\n",
      "1920/1920 [==============================] - 4s 2ms/step - loss: 0.0225 - accuracy: 0.9925 - val_loss: 0.0290 - val_accuracy: 0.9925\n",
      "Epoch 33/100\n",
      "1920/1920 [==============================] - 4s 2ms/step - loss: 0.0224 - accuracy: 0.9923 - val_loss: 0.0248 - val_accuracy: 0.9931\n",
      "Epoch 34/100\n",
      "1920/1920 [==============================] - 4s 2ms/step - loss: 0.0213 - accuracy: 0.9930 - val_loss: 0.0248 - val_accuracy: 0.9926\n",
      "Epoch 35/100\n",
      "1920/1920 [==============================] - 4s 2ms/step - loss: 0.0230 - accuracy: 0.9922 - val_loss: 0.0252 - val_accuracy: 0.9928\n",
      "Epoch 36/100\n",
      "1920/1920 [==============================] - 4s 2ms/step - loss: 0.0216 - accuracy: 0.9922 - val_loss: 0.0258 - val_accuracy: 0.9924\n",
      "Epoch 37/100\n",
      "1920/1920 [==============================] - 4s 2ms/step - loss: 0.0232 - accuracy: 0.9917 - val_loss: 0.0282 - val_accuracy: 0.9926\n",
      "Epoch 38/100\n",
      "1920/1920 [==============================] - 4s 2ms/step - loss: 0.0235 - accuracy: 0.9924 - val_loss: 0.0272 - val_accuracy: 0.9920\n",
      "Epoch 39/100\n",
      "1920/1920 [==============================] - 4s 2ms/step - loss: 0.0226 - accuracy: 0.9920 - val_loss: 0.0284 - val_accuracy: 0.9932\n",
      "Epoch 40/100\n",
      "1920/1920 [==============================] - 4s 2ms/step - loss: 0.0236 - accuracy: 0.9922 - val_loss: 0.0285 - val_accuracy: 0.9916\n",
      "Epoch 41/100\n",
      "1920/1920 [==============================] - 4s 2ms/step - loss: 0.0222 - accuracy: 0.9929 - val_loss: 0.0293 - val_accuracy: 0.9918\n",
      "Epoch 42/100\n",
      "1920/1920 [==============================] - 4s 2ms/step - loss: 0.0221 - accuracy: 0.9927 - val_loss: 0.0257 - val_accuracy: 0.9927\n",
      "Epoch 43/100\n",
      "1920/1920 [==============================] - 4s 2ms/step - loss: 0.0207 - accuracy: 0.9931 - val_loss: 0.0268 - val_accuracy: 0.9914\n",
      "Epoch 44/100\n",
      "1920/1920 [==============================] - 4s 2ms/step - loss: 0.0227 - accuracy: 0.9933 - val_loss: 0.0273 - val_accuracy: 0.9931\n",
      "Epoch 45/100\n",
      "1920/1920 [==============================] - 4s 2ms/step - loss: 0.0217 - accuracy: 0.9929 - val_loss: 0.0265 - val_accuracy: 0.9922\n",
      "Epoch 46/100\n",
      "1920/1920 [==============================] - 4s 2ms/step - loss: 0.0225 - accuracy: 0.9930 - val_loss: 0.0281 - val_accuracy: 0.9926\n",
      "Epoch 47/100\n",
      "1920/1920 [==============================] - 4s 2ms/step - loss: 0.0221 - accuracy: 0.9926 - val_loss: 0.0262 - val_accuracy: 0.9929\n",
      "Epoch 48/100\n",
      "1920/1920 [==============================] - 4s 2ms/step - loss: 0.0224 - accuracy: 0.9932 - val_loss: 0.0294 - val_accuracy: 0.9923\n",
      "Epoch 49/100\n",
      "1920/1920 [==============================] - 4s 2ms/step - loss: 0.0237 - accuracy: 0.9920 - val_loss: 0.0286 - val_accuracy: 0.9927\n",
      "Epoch 50/100\n",
      "1920/1920 [==============================] - 4s 2ms/step - loss: 0.0226 - accuracy: 0.9927 - val_loss: 0.0274 - val_accuracy: 0.9933\n",
      "Epoch 51/100\n",
      "1920/1920 [==============================] - 4s 2ms/step - loss: 0.0213 - accuracy: 0.9925 - val_loss: 0.0297 - val_accuracy: 0.9926\n",
      "Epoch 52/100\n",
      "1920/1920 [==============================] - 4s 2ms/step - loss: 0.0221 - accuracy: 0.9928 - val_loss: 0.0321 - val_accuracy: 0.9922\n",
      "Epoch 53/100\n",
      "1920/1920 [==============================] - 4s 2ms/step - loss: 0.0211 - accuracy: 0.9930 - val_loss: 0.0299 - val_accuracy: 0.9922\n",
      "Epoch 54/100\n",
      "1920/1920 [==============================] - 4s 2ms/step - loss: 0.0224 - accuracy: 0.9929 - val_loss: 0.0300 - val_accuracy: 0.9921\n",
      "Epoch 55/100\n",
      "1920/1920 [==============================] - 4s 2ms/step - loss: 0.0198 - accuracy: 0.9926 - val_loss: 0.0299 - val_accuracy: 0.9927\n",
      "Epoch 56/100\n",
      "1920/1920 [==============================] - 4s 2ms/step - loss: 0.0203 - accuracy: 0.9924 - val_loss: 0.0274 - val_accuracy: 0.9924\n",
      "Epoch 57/100\n",
      "1920/1920 [==============================] - 4s 2ms/step - loss: 0.0213 - accuracy: 0.9929 - val_loss: 0.0292 - val_accuracy: 0.9927\n",
      "Epoch 58/100\n",
      "1920/1920 [==============================] - 4s 2ms/step - loss: 0.0218 - accuracy: 0.9925 - val_loss: 0.0271 - val_accuracy: 0.9928\n",
      "Epoch 59/100\n",
      "1920/1920 [==============================] - 4s 2ms/step - loss: 0.0206 - accuracy: 0.9933 - val_loss: 0.0323 - val_accuracy: 0.9928\n",
      "Epoch 60/100\n",
      "1920/1920 [==============================] - 4s 2ms/step - loss: 0.0196 - accuracy: 0.9934 - val_loss: 0.0297 - val_accuracy: 0.9927\n",
      "Epoch 61/100\n",
      "1920/1920 [==============================] - 4s 2ms/step - loss: 0.0220 - accuracy: 0.9938 - val_loss: 0.0289 - val_accuracy: 0.9923\n",
      "Epoch 62/100\n",
      "1920/1920 [==============================] - 4s 2ms/step - loss: 0.0209 - accuracy: 0.9927 - val_loss: 0.0337 - val_accuracy: 0.9922\n",
      "Epoch 63/100\n",
      "1920/1920 [==============================] - 4s 2ms/step - loss: 0.0207 - accuracy: 0.9934 - val_loss: 0.0327 - val_accuracy: 0.9929\n",
      "Epoch 64/100\n",
      "1920/1920 [==============================] - 4s 2ms/step - loss: 0.0206 - accuracy: 0.9940 - val_loss: 0.0287 - val_accuracy: 0.9923\n",
      "Epoch 65/100\n",
      "1920/1920 [==============================] - 4s 2ms/step - loss: 0.0217 - accuracy: 0.9926 - val_loss: 0.0325 - val_accuracy: 0.9931\n",
      "Epoch 66/100\n",
      "1920/1920 [==============================] - 4s 2ms/step - loss: 0.0199 - accuracy: 0.9935 - val_loss: 0.0318 - val_accuracy: 0.9921\n",
      "Epoch 67/100\n",
      "1920/1920 [==============================] - 4s 2ms/step - loss: 0.0220 - accuracy: 0.9929 - val_loss: 0.0351 - val_accuracy: 0.9920\n",
      "Epoch 68/100\n",
      "1920/1920 [==============================] - 4s 2ms/step - loss: 0.0225 - accuracy: 0.9930 - val_loss: 0.0315 - val_accuracy: 0.9921\n",
      "Epoch 69/100\n",
      "1920/1920 [==============================] - 4s 2ms/step - loss: 0.0207 - accuracy: 0.9930 - val_loss: 0.0333 - val_accuracy: 0.9925\n",
      "Epoch 70/100\n",
      "1920/1920 [==============================] - 4s 2ms/step - loss: 0.0213 - accuracy: 0.9938 - val_loss: 0.0354 - val_accuracy: 0.9924\n",
      "Epoch 71/100\n",
      "1920/1920 [==============================] - 4s 2ms/step - loss: 0.0209 - accuracy: 0.9934 - val_loss: 0.0341 - val_accuracy: 0.9914\n",
      "Epoch 72/100\n",
      "1920/1920 [==============================] - 4s 2ms/step - loss: 0.0214 - accuracy: 0.9932 - val_loss: 0.0313 - val_accuracy: 0.9925\n",
      "Epoch 73/100\n",
      "1920/1920 [==============================] - 4s 2ms/step - loss: 0.0195 - accuracy: 0.9941 - val_loss: 0.0325 - val_accuracy: 0.9925\n",
      "Epoch 74/100\n",
      "1920/1920 [==============================] - 4s 2ms/step - loss: 0.0388 - accuracy: 0.9936 - val_loss: 0.0392 - val_accuracy: 0.9925\n",
      "Epoch 75/100\n",
      "1920/1920 [==============================] - 4s 2ms/step - loss: 0.0223 - accuracy: 0.9924 - val_loss: 0.0312 - val_accuracy: 0.9924\n",
      "Epoch 76/100\n",
      "1920/1920 [==============================] - 4s 2ms/step - loss: 0.0185 - accuracy: 0.9938 - val_loss: 0.0336 - val_accuracy: 0.9918\n",
      "Epoch 77/100\n",
      "1920/1920 [==============================] - 4s 2ms/step - loss: 0.0201 - accuracy: 0.9932 - val_loss: 0.0288 - val_accuracy: 0.9919\n",
      "Epoch 78/100\n",
      "1920/1920 [==============================] - 4s 2ms/step - loss: 0.0200 - accuracy: 0.9942 - val_loss: 0.0282 - val_accuracy: 0.9919\n",
      "Epoch 79/100\n",
      "1920/1920 [==============================] - 4s 2ms/step - loss: 0.0212 - accuracy: 0.9932 - val_loss: 0.0283 - val_accuracy: 0.9925\n",
      "Epoch 80/100\n",
      "1920/1920 [==============================] - 4s 2ms/step - loss: 0.0199 - accuracy: 0.9934 - val_loss: 0.0335 - val_accuracy: 0.9930\n",
      "Epoch 81/100\n",
      "1920/1920 [==============================] - 4s 2ms/step - loss: 0.0189 - accuracy: 0.9936 - val_loss: 0.0316 - val_accuracy: 0.9921\n",
      "Epoch 82/100\n",
      "1920/1920 [==============================] - 4s 2ms/step - loss: 0.0200 - accuracy: 0.9934 - val_loss: 0.0331 - val_accuracy: 0.9921\n",
      "Epoch 83/100\n",
      "1920/1920 [==============================] - 4s 2ms/step - loss: 0.0199 - accuracy: 0.9940 - val_loss: 0.0357 - val_accuracy: 0.9931\n",
      "Epoch 84/100\n",
      "1920/1920 [==============================] - 4s 2ms/step - loss: 0.0186 - accuracy: 0.9942 - val_loss: 0.0306 - val_accuracy: 0.9929\n",
      "Epoch 85/100\n",
      "1920/1920 [==============================] - 4s 2ms/step - loss: 0.0185 - accuracy: 0.9939 - val_loss: 0.0319 - val_accuracy: 0.9927\n",
      "Epoch 86/100\n",
      "1920/1920 [==============================] - 4s 2ms/step - loss: 0.0188 - accuracy: 0.9944 - val_loss: 0.0333 - val_accuracy: 0.9921\n",
      "Epoch 87/100\n",
      "1920/1920 [==============================] - 4s 2ms/step - loss: 0.0197 - accuracy: 0.9943 - val_loss: 0.0335 - val_accuracy: 0.9930\n",
      "Epoch 88/100\n",
      "1920/1920 [==============================] - 4s 2ms/step - loss: 0.0200 - accuracy: 0.9935 - val_loss: 0.0318 - val_accuracy: 0.9928\n",
      "Epoch 89/100\n",
      "1920/1920 [==============================] - 4s 2ms/step - loss: 0.0195 - accuracy: 0.9937 - val_loss: 0.0313 - val_accuracy: 0.9926\n",
      "Epoch 90/100\n",
      "1920/1920 [==============================] - 4s 2ms/step - loss: 0.0186 - accuracy: 0.9938 - val_loss: 0.0311 - val_accuracy: 0.9919\n",
      "Epoch 91/100\n",
      "1920/1920 [==============================] - 4s 2ms/step - loss: 0.0167 - accuracy: 0.9949 - val_loss: 0.0357 - val_accuracy: 0.9920\n",
      "Epoch 92/100\n",
      "1920/1920 [==============================] - 4s 2ms/step - loss: 0.0220 - accuracy: 0.9933 - val_loss: 0.0401 - val_accuracy: 0.9925\n",
      "Epoch 93/100\n",
      "1920/1920 [==============================] - 4s 2ms/step - loss: 0.0208 - accuracy: 0.9938 - val_loss: 0.0300 - val_accuracy: 0.9923\n",
      "Epoch 94/100\n",
      "1920/1920 [==============================] - 4s 2ms/step - loss: 0.0205 - accuracy: 0.9935 - val_loss: 0.0343 - val_accuracy: 0.9928\n",
      "Epoch 95/100\n",
      "1920/1920 [==============================] - 4s 2ms/step - loss: 0.0169 - accuracy: 0.9944 - val_loss: 0.0375 - val_accuracy: 0.9919\n",
      "Epoch 96/100\n",
      "1920/1920 [==============================] - 4s 2ms/step - loss: 0.0197 - accuracy: 0.9947 - val_loss: 0.0338 - val_accuracy: 0.9923\n",
      "Epoch 97/100\n",
      "1920/1920 [==============================] - 4s 2ms/step - loss: 0.0190 - accuracy: 0.9942 - val_loss: 0.0333 - val_accuracy: 0.9926\n",
      "Epoch 98/100\n",
      "1920/1920 [==============================] - 4s 2ms/step - loss: 0.0196 - accuracy: 0.9944 - val_loss: 0.0375 - val_accuracy: 0.9924\n",
      "Epoch 99/100\n",
      "1920/1920 [==============================] - 4s 2ms/step - loss: 0.0196 - accuracy: 0.9935 - val_loss: 0.0398 - val_accuracy: 0.9924\n",
      "Epoch 100/100\n",
      "1920/1920 [==============================] - 4s 2ms/step - loss: 0.0190 - accuracy: 0.9936 - val_loss: 0.0407 - val_accuracy: 0.9921\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x17d374d8910>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the Model\n",
    "model.fit(X_train, y_train, epochs=100, batch_size=20, verbose=1, validation_split=0.2, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "hollywood-swiss",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\vahidbabaey\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "y_pred_prob = model.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "plain-computer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[11748    40]\n",
      " [   74   138]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "y_pred_class1 = y_pred > 0.5\n",
    "cm = confusion_matrix(y_test, y_pred_class1)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "rolled-natural",
   "metadata": {},
   "outputs": [],
   "source": [
    "# True Negative\n",
    "TN = cm[0,0]\n",
    "\n",
    "# False Negative\n",
    "FN=cm[1,0]\n",
    "\n",
    "# False Positives\n",
    "FP = cm[0,1]\n",
    "\n",
    "# True Positives\n",
    "TP = cm[1,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "assumed-establishment",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sensitivity: 0.6509\n"
     ]
    }
   ],
   "source": [
    "# Calculating Sensitivity\n",
    "Sensitivity = TP / (TP + FN)\n",
    "print(f'Sensitivity: {Sensitivity:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fixed-alias",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Specificity: 0.9966\n"
     ]
    }
   ],
   "source": [
    "# Calculating Specificity\n",
    "Specificity = TN / (TN + FP)\n",
    "print(f'Specificity: {Specificity:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "weird-doctor",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.7753\n"
     ]
    }
   ],
   "source": [
    "# Precision\n",
    "Precision = TP / (TP + FP)\n",
    "print(f'Precision: {Precision:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "continuous-schema",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False positive rate: 0.0034\n"
     ]
    }
   ],
   "source": [
    "# Calculate False positive rate\n",
    "False_Positive_rate = FP / (FP + TN)\n",
    "print(f'False positive rate: {False_Positive_rate:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "gross-intellectual",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_class2 = y_pred > 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "double-latitude",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[11743    45]\n",
      " [   71   141]]\n"
     ]
    }
   ],
   "source": [
    "cm=confusion_matrix(y_test,y_pred_class2)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "lined-chaos",
   "metadata": {},
   "outputs": [],
   "source": [
    "# True Negative\n",
    "TN = cm[0,0]\n",
    "\n",
    "# False Negative\n",
    "FN=cm[1,0]\n",
    "\n",
    "# False Positives\n",
    "FP = cm[0,1]\n",
    "\n",
    "# True Positives\n",
    "TP = cm[1,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "nearby-score",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sensitivity: 0.6651\n"
     ]
    }
   ],
   "source": [
    "# Calculating Sensitivity\n",
    "Sensitivity = TP / (TP + FN)\n",
    "print(f'Sensitivity: {Sensitivity:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "terminal-thailand",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Specificity: 0.9962\n"
     ]
    }
   ],
   "source": [
    "# Calculating Specificity\n",
    "Specificity = TN / (TN + FP)\n",
    "print(f'Specificity: {Specificity:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "canadian-allen",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "#histogram of class distribution\n",
    "plt.hist(y_pred_prob, bins=100)\n",
    "plt.title(\"Histogram of Predicted Probabilities\")\n",
    "plt.xlabel(\"Predicted Probabilities of APS failure\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unique-affect",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
